{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0d32ee",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data with SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6e8e1",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84425a5",
   "metadata": {},
   "source": [
    "This notebook was created by [Jupyter AI](https://github.com/jupyterlab/jupyter-ai) with the following prompt:\n",
    "\n",
    "> /generate now create a similar notebook using scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c45c2",
   "metadata": {},
   "source": [
    " This Jupyter notebook offers an in-depth exploration of generating synthetic data akin to real-world observations utilizing the SciPy library in Python. It begins with introducing SciPy and its significance in creating simulated datasets, emphasizing that readers should have foundational programming skills in Python. The setup involves configuring a Jupyter Notebook environment and installing essential SciPy libraries such as numpy and scipy. Post installation, the notebook guides through importing these libraries to facilitate data generation tasks. Key methods of generating synthetic data are discussed, including utilizing statistical distributions or noise models provided by SciPy. It provides a detailed example of generating random numbers from specific distributions within SciPy, complete with code snippets for implementation. The notebook also covers saving and visualizing the generated data using CSV or JSON file formats along with visualization tools like matplotlib. For advanced users, there's an exploration of custom data generation by integrating or transforming existing SciPy functions, adding layers of complexity to the data simulation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4585e98",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8002ce5",
   "metadata": {},
   "source": [
    " ```python\n",
    "# Setting Up Your Environment\n",
    "# ==============================================\n",
    "# Ensure you have Jupyter Notebook installed\n",
    "# You can install it using pip: !pip install notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c72dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries from SciPy\n",
    "from scipy import constants, stats, optimize, integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f640f0",
   "metadata": {},
   "source": [
    "# Checking if SciPy is installed\n",
    "try:\n",
    "    import scipy\n",
    "    print(\"SciPy version:\", scipy.__version__)\n",
    "except ImportError:\n",
    "    print(\"SciPy not found. Installing now...\")\n",
    "    !pip install scipy\n",
    "    print(\"SciPy has been successfully installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1700c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the setup message\n",
    "print(\"\\nYour Jupyter Notebook environment is set up to use SciPy for generating data similar to real-world observations.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a92967",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf241d",
   "metadata": {},
   "source": [
    " ```python\n",
    "# Importing required libraries from SciPy suite\n",
    "import numpy as np  # For numerical operations, array manipulation, and high-level mathematical functions\n",
    "import scipy.stats as stats  # For generating statistical data distributions, optimization, integration, interpolation, signal processing, linear algebra, and image manipulation among other tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - NumPy is essential for numerical computing in Python, providing support for large multi-dimensional arrays and matrices, along with a wide range of high-level mathematical functions to operate on these arrays.\n",
    "# - SciPy extends the capabilities of NumPy with more specialized functions for various tasks including optimization, integration, interpolation, signal processing, linear algebra, and image manipulation among other tasks. In this section, we are particularly interested in its submodule scipy.stats which contains a large number of probability distributions that can be used to generate synthetic data similar to real-world observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84456570",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data with SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2429c",
   "metadata": {},
   "source": [
    " ```python\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad455c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f07be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Generating Synthetic Data with SciPy\n",
    "print(\"Generating synthetic data using statistical distributions and noise models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using a Normal Distribution\n",
    "mean = 0\n",
    "std_dev = 1\n",
    "size = 1000\n",
    "data_normal = np.random.normal(mean, std_dev, size)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(data_normal, bins=30, density=True, alpha=0.65, label='Normal Distribution')\n",
    "plt.title('Histogram of Normal Distribution Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using a Uniform Distribution\n",
    "low = 0\n",
    "high = 1\n",
    "data_uniform = np.random.uniform(low, high, size)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(data_uniform, bins=30, density=True, alpha=0.65, label='Uniform Distribution')\n",
    "plt.title('Histogram of Uniform Distribution Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Adding Noise to a Signal (e.g., using a Gaussian Noise Model)\n",
    "signal = np.linspace(0, 10, size)\n",
    "noise_std = 1\n",
    "data_noisy = signal + np.random.normal(0, noise_std, size)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(signal, label='Signal')\n",
    "plt.scatter(range(size), data_noisy, color='red', label='Noisy Signal')\n",
    "plt.title('Signal with Gaussian Noise')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd12485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 4: Using a Poisson Distribution for Count Data\n",
    "lambda_val = 5\n",
    "data_poisson = np.random.poisson(lambda_val, size)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(data_poisson, bins=range(int(max(data_poisson))+1), density=True, alpha=0.65, label='Poisson Distribution')\n",
    "plt.title('Histogram of Poisson Distribution Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531e684",
   "metadata": {},
   "source": [
    "## Example: Generating Random Numbers from a Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600f162",
   "metadata": {},
   "source": [
    " ```python\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a31c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Generating Random Numbers from a Distribution\n",
    "print(\"Generating random numbers from predefined distributions in SciPy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4000f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Choose a distribution\n",
    "distribution = 'normal'  # Supported distribution: normal (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923be6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define parameters for the chosen distribution\n",
    "if distribution == 'normal':\n",
    "    mu, sigma = 0, 1  # Parameters for the normal distribution: mean and standard deviation\n",
    "elif distribution == 'uniform':\n",
    "    low, high = 0, 1  # Parameters for the uniform distribution: lower and upper bounds\n",
    "elif distribution == 'exponential':\n",
    "    scale = 1  # Parameter for the exponential distribution: scale parameter\n",
    "else:\n",
    "    raise ValueError(\"Unsupported distribution. Please choose from predefined distributions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate random numbers from the chosen distribution\n",
    "num_samples = 1000  # Number of samples to generate\n",
    "if distribution == 'normal':\n",
    "    random_numbers = stats.norm.rvs(loc=mu, scale=sigma, size=num_samples)\n",
    "elif distribution == 'uniform':\n",
    "    random_numbers = stats.uniform.rvs(loc=low, scale=high - low, size=num_samples)\n",
    "elif distribution == 'exponential':\n",
    "    random_numbers = stats.expon.rvs(scale=scale, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Plotting the generated random numbers\n",
    "plt.figure(figsize=(10, 6))\n",
    "if distribution == 'normal':\n",
    "    plt.hist(random_numbers, bins=30, density=True, alpha=0.65, color='g')\n",
    "    x = np.linspace(mu - 3*sigma, mu + 3*sigma, num=100)\n",
    "    plt.plot(x, stats.norm.pdf(x, loc=mu, scale=sigma), 'r-', lw=2, label='Normal distribution')\n",
    "elif distribution == 'uniform':\n",
    "    plt.hist(random_numbers, bins=30, density=True, alpha=0.65, color='b')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.axvline(x=low, color='r', linestyle='--')\n",
    "    plt.axvline(x=high, color='g', linestyle='--')\n",
    "elif distribution == 'exponential':\n",
    "    plt.hist(random_numbers, bins=30, density=True, alpha=0.65, color='m')\n",
    "    x = np.linspace(0, mu + 3*sigma, num=100)\n",
    "    plt.plot(x, stats.expon.pdf(x, scale=scale), 'c-', lw=2, label='Exponential distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Histogram of Generated Random Numbers from a {} Distribution'.format(distribution))\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random numbers generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb94c7c",
   "metadata": {},
   "source": [
    "## Saving and Visualizing Generated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce9355",
   "metadata": {},
   "source": [
    " ```python\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data using SciPy\n",
    "mean = 0\n",
    "std_dev = 1\n",
    "num_samples = 1000\n",
    "generated_data = norm.rvs(loc=mean, scale=std_dev, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c66a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated data to a CSV file\n",
    "csv_file_path = 'generated_data.csv'\n",
    "np.savetxt(csv_file_path, generated_data, delimiter=',')\n",
    "print(f\"Generated data saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated data to a JSON file\n",
    "json_file_path = 'generated_data.json'\n",
    "data_dict = {'data': generated_data.tolist()}\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(data_dict, f)\n",
    "print(f\"Generated data saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a66433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated data using matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(generated_data, bins=30, density=True, alpha=0.65, color='g', label='Generated Data')\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mean, std_dev)\n",
    "plt.plot(x, p, 'k', linewidth=2, label='Normal Distribution')\n",
    "plt.title('Histogram of Generated Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data validation\n",
    "mean_generated = np.mean(generated_data)\n",
    "std_dev_generated = np.std(generated_data)\n",
    "print(f\"Mean of generated data: {mean_generated}\")\n",
    "print(f\"Standard deviation of generated data: {std_dev_generated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the mean and standard deviation are close to the expected values\n",
    "expected_mean = 0\n",
    "expected_std_dev = 1\n",
    "tolerance = 0.1\n",
    "if abs(mean_generated - expected_mean) < tolerance and abs(std_dev_generated - expected_std_dev) < tolerance:\n",
    "    print(\"Data validation passed: Mean and standard deviation are within the acceptable tolerance.\")\n",
    "else:\n",
    "    print(\"Data validation failed: Mean or standard deviation is out of tolerance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246c3b6",
   "metadata": {},
   "source": [
    "## Advanced Topics: Custom Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf7bf2",
   "metadata": {},
   "source": [
    " ```python\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, expon, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate custom data based on a mixture of Gaussians\n",
    "def generate_mixture_of_gaussians(num_samples, means, covs, weights):\n",
    "    \"\"\"\n",
    "    Generates data from a mixture of Gaussian distributions.\n",
    "    \n",
    "    Parameters:\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        means (list or array-like): Means of the Gaussian components.\n",
    "        covs (list or array-like): Covariance matrices of the Gaussian components.\n",
    "        weights (list or array-like): Weights for each Gaussian component.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Generated data samples.\n",
    "    \"\"\"\n",
    "    if len(means) != len(covs) or len(means) != len(weights):\n",
    "        raise ValueError(\"The number of means, covariances, and weights must be the same.\")\n",
    "    \n",
    "    num_components = len(means)\n",
    "    data = np.zeros((num_samples, len(means[0])))\n",
    "    \n",
    "    # Generate each component's contribution to the mixture\n",
    "    contributions = np.random.choice(range(num_components), size=num_samples, p=weights)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        comp = contributions[i]\n",
    "        data[i] = np.random.multivariate_normal(mean=means[comp], cov=covs[comp])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Generate 1000 samples from a mixture of two Gaussians\n",
    "num_samples = 1000\n",
    "means = [np.array([0, 0]), np.array([5, 5])]\n",
    "covs = [np.eye(2), np.eye(2)]\n",
    "weights = [0.4, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_data = generate_mixture_of_gaussians(num_samples, means, covs, weights)\n",
    "print(\"Generated Mixture of Gaussians Data:\\n\", mixture_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate custom data based on an exponential distribution mixed with uniform noise\n",
    "def generate_exponential_uniform_mixture(num_samples, rate):\n",
    "    \"\"\"\n",
    "    Generates data from an exponential distribution mixed with uniform noise.\n",
    "    \n",
    "    Parameters:\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        rate (float): Rate parameter for the exponential distribution.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Generated data samples.\n",
    "    \"\"\"\n",
    "    if rate <= 0:\n",
    "        raise ValueError(\"Rate must be positive.\")\n",
    "    \n",
    "    # Generate uniform noise\n",
    "    uniform_noise = uniform.rvs(size=num_samples)\n",
    "    \n",
    "    # Generate exponential distribution based on the noise\n",
    "    exponential_data = expon.ppf(uniform_noise, scale=1/rate)\n",
    "    \n",
    "    return exponential_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eebb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Generate 500 samples from an exponential distribution with rate 2\n",
    "num_samples = 500\n",
    "rate = 2\n",
    "exponential_mixture_data = generate_exponential_uniform_mixture(num_samples, rate)\n",
    "print(\"\\nGenerated Exponential-Uniform Mixture Data:\\n\", exponential_mixture_data[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
